# Grafana Dashboard for AI Platform

---
# Grafana ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-dashboards
  namespace: ai-platform
  labels:
    grafana_dashboard: "1"
data:
  ai-platform-overview.json: |
    {
      "dashboard": {
        "title": "AI Platform Overview",
        "tags": ["ai-platform"],
        "timezone": "browser",
        "refresh": "30s",
        "panels": [
          {
            "id": 1,
            "title": "Total Requests",
            "type": "graph",
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0},
            "targets": [
              {
                "expr": "sum(rate(ai_platform_requests_total[5m]))",
                "legendFormat": "Requests/sec"
              }
            ]
          },
          {
            "id": 2,
            "title": "Request Duration (P95)",
            "type": "graph",
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0},
            "targets": [
              {
                "expr": "histogram_quantile(0.95, sum(rate(ai_platform_request_duration_seconds_bucket[5m])) by (le))",
                "legendFormat": "P95 Latency"
              }
            ]
          },
          {
            "id": 3,
            "title": "Requests by Feature",
            "type": "graph",
            "gridPos": {"h": 8, "w": 24, "x": 0, "y": 8},
            "targets": [
              {
                "expr": "sum(rate(ai_platform_requests_total[5m])) by (feature)",
                "legendFormat": "{{feature}}"
              }
            ]
          },
          {
            "id": 4,
            "title": "Error Rate",
            "type": "graph",
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 16},
            "targets": [
              {
                "expr": "sum(rate(ai_platform_requests_total{status=\"error\"}[5m])) / sum(rate(ai_platform_requests_total[5m])) * 100",
                "legendFormat": "Error Rate %"
              }
            ]
          },
          {
            "id": 5,
            "title": "Active Services",
            "type": "stat",
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 16},
            "targets": [
              {
                "expr": "sum(ai_platform_service_status)",
                "legendFormat": "Healthy Services"
              }
            ]
          },
          {
            "id": 6,
            "title": "Cost by Provider",
            "type": "piechart",
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 24},
            "targets": [
              {
                "expr": "sum(ai_platform_cost_total) by (provider_type)",
                "legendFormat": "{{provider_type}}"
              }
            ]
          },
          {
            "id": 7,
            "title": "Queue Depth",
            "type": "graph",
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 24},
            "targets": [
              {
                "expr": "ai_platform_queue_depth",
                "legendFormat": "{{feature}} - {{provider_id}}"
              }
            ]
          },
          {
            "id": 8,
            "title": "Provider Latency",
            "type": "graph",
            "gridPos": {"h": 8, "w": 24, "x": 0, "y": 32},
            "targets": [
              {
                "expr": "histogram_quantile(0.95, sum(rate(ai_platform_provider_latency_seconds_bucket[5m])) by (provider_id, le))",
                "legendFormat": "{{provider_id}}"
              }
            ]
          },
          {
            "id": 9,
            "title": "Service CPU Usage",
            "type": "graph",
            "gridPos": {"h": 8, "w": 24, "x": 0, "y": 40},
            "targets": [
              {
                "expr": "ai_platform_service_cpu_usage_percent",
                "legendFormat": "{{service_id}}"
              }
            ]
          },
          {
            "id": 10,
            "title": "Service GPU Usage",
            "type": "graph",
            "gridPos": {"h": 8, "w": 24, "x": 0, "y": 48},
            "targets": [
              {
                "expr": "ai_platform_service_gpu_usage_percent",
                "legendFormat": "{{service_id}} - {{gpu_id}}"
              }
            ]
          }
        ]
      }
    }
  ai-platform-scaling.json: |
    {
      "dashboard": {
        "title": "AI Platform Scaling",
        "tags": ["ai-platform", "scaling"],
        "timezone": "browser",
        "refresh": "30s",
        "panels": [
          {
            "id": 1,
            "title": "Current Replicas",
            "type": "stat",
            "gridPos": {"h": 8, "w": 8, "x": 0, "y": 0},
            "targets": [
              {
                "expr": "sum(kube_deployment_status_replicas{namespace=\"ai-platform\"}) by (deployment)",
                "legendFormat": "{{deployment}}"
              }
            ]
          },
          {
            "id": 2,
            "title": "Scale Events",
            "type": "table",
            "gridPos": {"h": 8, "w": 16, "x": 8, "y": 0},
            "targets": [
              {
                "expr": "ai_platform_scale_events_total",
                "legendFormat": "{{feature_id}} - {{action}}"
              }
            ]
          },
          {
            "id": 3,
            "title": "Scale Up Events Timeline",
            "type": "graph",
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 8},
            "targets": [
              {
                "expr": "increase(ai_platform_scale_events_total{action=\"scale_up\"}[1h])",
                "legendFormat": "{{feature_id}}"
              }
            ]
          },
          {
            "id": 4,
            "title": "Scale Down Events Timeline",
            "type": "graph",
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 8},
            "targets": [
              {
                "expr": "increase(ai_platform_scale_events_total{action=\"scale_down\"}[1h])",
                "legendFormat": "{{feature_id}}"
              }
            ]
          }
        ]
      }
    }
  grafana.ini: |
    [server]
    root_url = %(protocol)s://%(domain)s:%(http_port)s/grafana

    [users]
    default_theme = dark

    [auth.anonymous]
    enabled = true
    org_role = Viewer

    [dashboards]
    default_home_dashboard_path = /etc/grafana/provisioning/dashboards/ai-platform-overview.json

---
# Grafana Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grafana
  namespace: ai-platform
  labels:
    app: grafana
spec:
  replicas: 1
  selector:
    matchLabels:
      app: grafana
  template:
    metadata:
      labels:
        app: grafana
    spec:
      containers:
        - name: grafana
          image: grafana/grafana:10.1.0
          ports:
            - name: web
              containerPort: 3000
              protocol: TCP
          env:
            - name: GF_SECURITY_ADMIN_USER
              value: "admin"
            - name: GF_SECURITY_ADMIN_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: grafana-secret
                  key: admin-password
            - name: GF_SERVER_ROOT_URL
              value: "http://localhost:3000"
          volumeMounts:
            - name: config
              mountPath: /etc/grafana/grafana.ini
              subPath: grafana.ini
            - name: dashboards
              mountPath: /etc/grafana/provisioning/dashboards
            - name: storage
              mountPath: /var/lib/grafana
          livenessProbe:
            httpGet:
              path: /api/health
              port: web
            initialDelaySeconds: 10
            periodSeconds: 10
          readinessProbe:
            httpGet:
              path: /api/health
              port: web
            initialDelaySeconds: 5
            periodSeconds: 5
          resources:
            requests:
              cpu: 100m
              memory: 128Mi
            limits:
              cpu: 500m
              memory: 512Mi
      volumes:
        - name: config
          configMap:
            name: grafana-dashboards
        - name: dashboards
          configMap:
            name: grafana-dashboards
        - name: storage
          emptyDir: {}
---
# Grafana Secret
apiVersion: v1
kind: Secret
metadata:
  name: grafana-secret
  namespace: ai-platform
type: Opaque
stringData:
  admin-password: "admin123"
---
# Grafana Service
apiVersion: v1
kind: Service
metadata:
  name: grafana
  namespace: ai-platform
  labels:
    app: grafana
spec:
  type: ClusterIP
  ports:
    - name: web
      port: 3000
      targetPort: web
      protocol: TCP
  selector:
    app: grafana
---
# Grafana Ingress
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: grafana-ingress
  namespace: ai-platform
  annotations:
    kubernetes.io/ingress.class: "nginx"
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
    - host: grafana.ai-platform.example.com
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: grafana
                port:
                  number: 3000
